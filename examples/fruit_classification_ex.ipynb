{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67b48c30",
   "metadata": {},
   "source": [
    "# 🍏 Fruit & Veg Quality Project\n",
    "\n",
    "This project uses **TensorFlow Lite** and **Edge Impulse** to classify fruit freshness.\n",
    "\n",
    "- Supports Raspberry Pi Zero 2W  \n",
    "- Optimized with EON Compiler  \n",
    "- Inference time: *5ms*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115df784",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fe5b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tflite_runtime.interpreter as tflite\n",
    "\n",
    "from src.utils import MODEL_PATH, LABELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc812e88",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2755c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8901719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf48bbf",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6ccfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_classification(img_path, apply_softmax=False) -> None:\n",
    "    \"\"\"\n",
    "    Classify an image using a TensorFlow Lite model.\n",
    "    Args:\n",
    "        img_path (str): Path to the input image.\n",
    "        apply_softmax (bool): Whether to apply softmax to the output probabilities.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    img = Image.open(img_path)\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    model_path = MODEL_PATH\n",
    "\n",
    "    labels = LABELS\n",
    "    \n",
    "    top_k_results=3\n",
    "\n",
    "    # Load the TFLite model\n",
    "    interpreter = tflite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # Get input and output tensors\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    # Preprocess\n",
    "    img = img.resize((input_details[0]['shape'][1], \n",
    "                      input_details[0]['shape'][2]))\n",
    "    \n",
    "    input_dtype = input_details[0]['dtype']\n",
    "    \n",
    "    if input_dtype == np.uint8:\n",
    "        input_data = np.expand_dims(np.array(img), axis=0)\n",
    "    elif input_dtype == np.int8:\n",
    "        scale, zero_point = input_details[0]['quantization']\n",
    "        img_array = np.array(img, dtype=np.float32) / 255.0\n",
    "        img_array = (img_array / scale + zero_point).clip(-128, 127).astype(np.int8)\n",
    "        input_data = np.expand_dims(img_array, axis=0)\n",
    "    else:  # float32\n",
    "        input_data = np.expand_dims(np.array(img, dtype=np.float32), axis=0) / 255.0\n",
    "\n",
    "    # Inference on Raspi-Zero\n",
    "    start_time = time.time()\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "    end_time = time.time()\n",
    "    inference_time = (end_time - start_time) * 1000  # Convert to milliseconds\n",
    "\n",
    "    # Obtain results\n",
    "    predictions = interpreter.get_tensor(output_details[0]['index'])[0]\n",
    "\n",
    "    # Get indices of the top k results\n",
    "    top_k_indices = np.argsort(predictions)[::-1][:top_k_results]\n",
    "\n",
    "    # Handle output based on type\n",
    "    output_dtype = output_details[0]['dtype']\n",
    "    if output_dtype in [np.int8, np.uint8]:\n",
    "        # Dequantize the output\n",
    "        scale, zero_point = output_details[0]['quantization']\n",
    "        predictions = (predictions.astype(np.float32) - zero_point) * scale\n",
    "    \n",
    "    if apply_softmax:\n",
    "        # Apply softmax\n",
    "        exp_preds = np.exp(predictions - np.max(predictions))\n",
    "        probabilities = exp_preds / np.sum(exp_preds)\n",
    "    else:\n",
    "        probabilities = predictions\n",
    "\n",
    "    print(\"\\n\\t[PREDICTION]        [Prob]\\n\")\n",
    "    for i in range(top_k_results):\n",
    "        print(\"\\t{:20}: {:.1f}%\".format(\n",
    "            labels[top_k_indices[i]],\n",
    "            probabilities[top_k_indices[i]] * 100))\n",
    "    print (\"\\n\\tInference time: {:.1f}ms\".format(inference_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050cb77f",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ea14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"../images/example1.jpg\"\n",
    "image_classification(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3cffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"../images/example2.jpg\"\n",
    "image_classification(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c4200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"../images/example3.jpg\"\n",
    "image_classification(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9898df",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"../images/example4.jpg\"\n",
    "image_classification(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e373b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"../images/example5.jpg\"\n",
    "image_classification(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abcb956",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"../images/example6.jpg\"\n",
    "image_classification(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28037688",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"../images/example7.jpg\"\n",
    "image_classification(img_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
